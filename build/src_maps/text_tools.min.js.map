{"version":3,"sources":["text_tools.min.js","cool.js","CFGGenerator.js","Markov.js"],"names":["choice","choices","Array","isArray","arguments","Math","floor","random","length","chance","n","module","exports","coinFlip","require","Markov","CFGGenerator","params","cfgFiles","tagChance","filterChance","removeChance","callback","grammars","markovs","overrides","shareOverrides","undefined","defaultMarkovParams","max","useMarkov","defaultSentenceType","overrideAddTagChance","overrideFilterChance","overrideRemoveChance","overridePosKeys","overrideFilter","expand","gid","start","expansion","override","filter","prev","pick","i","console","log","push","word","pos","splice","indexOf","picks","p","includes","substring","formatSentence","text","map","e","join","replace","toUpperCase","puncs","match","forEach","m","r","this","isReady","Object","keys","async","f","url","cfgData","fetch","then","response","json","feed","loadGrammarFiles","k","seq","pop","concat","_","addOverrides","tags","gids","g","updateOverrides","shift","clearOverrides","getSentence","st","over","getSequence","split","sent","getText","JSON","parse","result","window","Number","ngrams","beginnings","tokenize","tokens","beginning","slice","gram","next","hasOwnProperty","current","output","generate"],"mappings":"CAAE,WACF,aCGA,SAAAA,EAAAC,GAEA,OADAC,MAAAC,QAAAF,KAAAA,EAAA,IAAAG,YACAH,EAAAI,KAAAC,MAAAD,KAAAE,SAAAN,EAAAO,QACA,CAEA,SAAAC,EAAAC,GACA,OAAAL,KAAAE,OAAA,GAAAG,CACA,CCFA,GDIA,oBAAAC,SACAA,OAAAC,QAAA,CAAAC,SAdA,WACA,OAAAR,KAAAE,SAAA,EACA,EAYAP,SAAAS,WCLA,oBAAAE,OAAA,CACA,MAAAE,SAAAA,EAAAb,OAAAA,EAAAS,OAAAA,GAAAK,QAAA,cACAC,OAAAA,GAAAD,QAAA,cACA,CAEA,SAAAE,EAAAC,GAEAA,IAAAA,EAAA,CAAA,GACA,IAAAC,SAAAA,EAAAC,UAAAA,EAAAC,aAAAA,EAAAC,aAAAA,EAAAC,SAAAA,GAAAL,EAEAM,EAAA,CAAA,EACAC,EAAA,CAAA,EACAC,EAAA,CAAA,EACAC,OAAAC,IAAAV,EAAAS,gBAAAT,EAAAS,eAEAE,EAAA,CAAAlB,EAAA,EAAAmB,IAAA,IAGAC,GADAb,EAAAc,oBACAd,EAAAa,YAAA,GAEAE,EAAAb,GAAA,GACAc,EAAAb,GAAA,GACAc,EAAAb,GAAA,GAGAc,EAAA,CAAA,EACAC,EAAA,CAAA,EAkDA,SAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,GAEA,GAAAF,EAAAF,IACAE,EAAAF,GAAA/B,OAAA,EAAA,CACA,IAAAoC,EAAA5C,EAAAyC,EAAAF,IACA,GAAArC,MAAAC,QAAAyC,GACA,IAAA,IAAAC,EAAA,EAAAA,EAAAD,EAAApC,OAAAqC,IACAR,EAAAC,EAAAM,EAAAC,GAAAL,EAAAC,EAAAC,EAAAH,OAGA,OAAAA,GAAAO,QAAAC,IAAA,KAAAH,GACAJ,EAAAQ,KAAA,CAAAC,KAAAL,EAAAM,IAAAX,IAGAE,EAAAF,GAAAY,OAAAV,EAAAF,GAAAa,QAAAR,GAAA,GAEA,OAAAJ,CACA,CAEA,GAAAjB,EAAAe,GAAAC,GAAA,CAEA,IAGAK,EAHAS,EAAAX,EAAAH,GACAhB,EAAAe,GAAAC,GAAAG,QAAAY,GAAAA,EAAAC,SAAAb,EAAAH,MACAhB,EAAAe,GAAAC,GAGAK,EADA,IAAAS,EAAA7C,OACAR,EAAAuB,EAAAe,GAAAC,IAEAvC,EAAAqD,GAGA,IAAA,IAAAR,EAAA,EAAAA,EAAAD,EAAApC,OAAAqC,IACAR,EAAAC,EAAAM,EAAAC,GAAAL,EAAAC,EAAAC,EAAAH,EAEA,KAAA,CAGA,IAAAU,EAAAV,EACAW,EAAAP,EAEA,GADA,OAAAJ,IAAAU,EAAAT,EAAAA,EAAAhC,OAAA,GAAAyC,MACA,MAAAV,EAAA,GAAA,CACAW,EAAAX,EAAAiB,UAAA,GACA,IAAA,IAAAX,EAAAL,EAAAhC,OAAA,EAAAqC,GAAA,EAAAA,IACA,GAAAL,EAAAK,GAAAK,MAAAA,EAAA,CACAD,EAAAT,EAAAK,GAAAI,KACA,KACA,CAEA,CACAT,EAAAQ,KAAA,CAAAC,KAAAA,EAAAC,IAAAA,GACA,CACA,OAAAV,CACA,CAEA,SAAAiB,EAAAjB,GACA,IAAAkB,EAAAlB,EAAAmB,KAAAC,GAAAA,EAAAX,OAAAY,KAAA,KACAH,EAAAA,EAAAI,QAAA,kBAAA,IAEAJ,EAAAA,EAAAI,QAAA,oBAAA,OACAJ,EAAAA,EAAAI,QAAA,qBAAA,MAEAJ,EAAAA,EAAAI,QAAA,SAAA,KACAJ,EAAAA,EAAAI,QAAA,UAAA,MACAJ,EAAAA,EAAA,GAAAK,cAAAL,EAAAF,UAAA,EAAAE,EAAAlD,QAGA,IAAAwD,EAAAN,EAAAO,MAAA,oBAQA,OAPAD,GACAA,EAAAE,SAAAC,IACA,IAAAC,EAAAD,EAAAX,UAAA,EAAAW,EAAA3D,OAAA,GAAA2D,EAAAA,EAAA3D,OAAA,GAAAuD,cACAL,EAAAA,EAAAI,QAAAK,EAAAC,EAAA,IAIAV,CACA,CA3HAW,KAAAC,SAAA,EACApD,GACAqD,OAAAC,KAAAtD,GAAAV,OAAA,GAKAiE,iBACA,IAAA,MAAAC,KAAAxD,EAAA,CACA,MAAAyD,EAAAzD,EAAAwD,GACAE,QAAAC,MAAAF,GAAAG,MAAAC,GAAAA,EAAAC,SAEAX,KAAAY,KAAAP,EAAAE,EACA,CAEA,CAZAM,GAcAb,KAAAY,KAAA,SAAA3C,EAAA0C,GACAvD,EAAAa,KAAAb,EAAAa,GAAA,CAAA,GACAf,EAAAe,KAAAf,EAAAe,GAAA,CAAA,GACAd,EAAAc,KAAAd,EAAAc,GAAA,CAAA,GAEA,IAAA,MAAA6C,KAAAH,EAGA,GAFAzD,EAAAe,GAAA6C,GAAAH,EAAAG,GAEArD,GAvCA,OAuCAyB,SAAA4B,GAAA,CACA3D,EAAAc,GAAA6C,GAAA,IAAApE,EAAAa,GACA,IAAA,IAAAiB,EAAA,EAAAA,EAAAmC,EAAAG,GAAA3E,OAAAqC,IAAA,CACA,IAAAuC,EAAA,IAAAJ,EAAAG,GAAAtC,IACAuC,EAAAC,MACA7D,EAAAc,GAAA6C,GAAAF,KAAAG,EAAAvB,KAAA,KACA,CACA,CAGA1B,EAAAG,KAAAH,EAAAG,GAAA,IACAF,EAAAE,KAAAF,EAAAE,GAAA,IACAH,EAAAG,GAAAH,EAAAG,GACAgD,OAAAf,OAAAC,KAAAjD,EAAAe,IAAAI,QAAAyC,GAAAA,EAAA3E,OAAA,KACA4B,EAAAE,GAAAF,EAAAE,GACAgD,OAAAnD,EAAAG,GAAAI,QAAA6C,GAAA9E,EAAAwB,OAEAoC,KAAAC,SAAAC,OAAAC,KAAAjD,EAAAe,IAAA9B,OAAA,IACA6D,KAAAC,SAAA,EACAhD,GAAAA,IAEA,EA+EA+C,KAAAmB,aAAA,SAAAlD,EAAAmD,EAAAtE,GAEAM,EAAAa,KACAb,EAAAa,GAAA,CAAA,EACAH,EAAAG,GAAAiC,OAAAC,KAAAjD,EAAAe,IAAAI,QAAAyC,GAAAA,EAAA3E,OAAA,IACA4B,EAAAE,GAAAH,EAAAG,GAAAI,QAAA6C,GAAA9E,EAAAwB,MAGA,MAAAyD,EAAAhE,EAAA6C,OAAAC,KAAAjD,GAAA,CAAAe,GAGA,IAAA,IAAAO,EAAA,EAAAA,EAAA6C,EAAAlF,OAAAqC,IAAA,CACA,MAAA8C,EAAAD,EAAA7C,GACA,IAAA,IAAAA,EAAA,EAAAA,EAAA4C,EAAAjF,OAAA,EAAAqC,IAAA,CACA,IAAApC,EAAAU,GAAA,GAAA,SACA,MAAA+B,IAAAA,EAAAD,KAAAA,GAAAwC,EAAA5C,GACAT,EAAAuD,GAAApC,SAAAL,KACAzB,EAAAkE,GAAAzC,KAAAzB,EAAAkE,GAAAzC,GAAA,IACAzB,EAAAkE,GAAAzC,GAAAK,SAAAN,IACAxB,EAAAkE,GAAAzC,GAAAF,KAAAC,GAEA,CACA,CACA,EAGAoB,KAAAuB,gBAAA,SAAAtD,EAAAjB,GAEA,IAAA,MAAA6B,KAAAzB,EAAAa,GACA7B,EAAAY,IACAI,EAAAa,GAAAY,GAAA2C,QAIApF,EAAAY,IAAAe,EAAAE,GAAAuD,QACApF,EAAAY,IAAAe,EAAAE,GAAAU,KAAAhD,EAAAmC,EAAAG,GAAAI,QAAAQ,IAAAd,EAAAE,GAAAiB,SAAAL,MACA,EAGAmB,KAAAyB,eAAA,WACA,IAAA,MAAAxD,KAAAb,EACAA,EAAAa,GAAA,CAAA,CAEA,EAIA+B,KAAA0B,YAAA,SAAAzD,EAAA0D,EAAAR,EAAA9C,GACA,IAAAuD,EAAA,IAAAxE,EAAAa,IACAR,IAAAmE,EAAAD,GAAA,CAAA,IAAAxE,EAAAc,GAAA0D,GAAAE,cAAAC,MAAA,KAAA,OACA,IAAAC,EAAA/B,KAAAgC,QAAA/D,EAAA0D,EAAAC,EAAAvD,GAKA,OAJA8C,IACAnB,KAAAmB,aAAAlD,EAAA8D,EAAAX,KAAAzD,GACAqC,KAAAuB,gBAAAtD,EAAAJ,IAEAkE,EAAA1C,IACA,EAGAW,KAAAgC,QAAA,SAAA/D,EAAA0D,EAAAvD,EAAAC,GAEA,iBAAAD,IAAAA,EAAA6D,KAAAC,MAAA9D,IACAA,EAAAuD,KACAzE,EAAAe,GAAA0D,KAAAA,EAAA,KACAzE,EAAAe,GAAA0D,GAAAxF,SAAAwF,EAAA,MAEA,IAAAQ,EAAAnE,EAAAC,EAAA0D,EAAA,GAAAvD,GAAA,CAAA,EAAAC,GAAA,CAAA,GAEA,MAAA,CAAAgB,KAAAD,EAAA+C,GAAAf,KAAAe,EACA,CACA,CCxOA,GD0OA,oBAAA7F,SACAA,OAAAC,QAAA,CAAAI,iBAGA,oBAAAyF,SACAA,OAAAzF,aAAAA,GC/OA,oBAAAL,OAAA,CACA,MAAAE,SAAAA,EAAAb,OAAAA,EAAAS,OAAAA,GAAAK,QAAA,YACA,CAEA,SAAAC,EAAAE,GACAP,EAAAgG,OAAAzF,EAAAP,GACAmB,IAAA6E,OAAAzF,EAAAY,KAEA,IAAA8E,EAAA,CAAA,EACAC,EAAA,GAGA,SAAAC,EAAAnD,GACA,OAAAA,EAAAyC,MAAA,MACA,CAEA9B,KAAAY,KAAA,SAAAvB,GACA,IAAAoD,EAAAD,EAAAnD,GACA,GAAAoD,EAAAtG,OAAAE,EAAA,OAAA,EAGA,IAAAqG,EAAAD,EAAAE,MAAA,EAAAtG,GAAAmD,KAAA,KACA+C,EAAA5D,KAAA+D,GAGA,IAAA,IAAAlE,EAAA,EAAAA,EAAAiE,EAAAtG,OAAAE,EAAAmC,IAAA,CACA,IAAAoE,EAAAC,EAEAD,EAAAH,EAAAE,MAAAnE,EAAAA,EAAAnC,GAAAmD,KAAA,KACAqD,EAAAJ,EAAAjE,EAAAnC,GAEAiG,EAAAQ,eAAAF,KAAAN,EAAAM,GAAA,IACAN,EAAAM,GAAAjE,KAAAkE,EACA,CACA,EA6BA7C,KAAA6B,YAAA,WACA,OA5BA,WAGAkB,QAAApH,EAAA4G,GACA,IAAAS,EAAAR,EAAAO,SAGA,IAAA,IAAAvE,EAAA,EAAAA,EAAAhB,KAEA8E,EAAAQ,eAAAC,SAFAvE,IAEA,CACA,IAEAqE,EAAAlH,EAFA2G,EAAAS,UAIAC,EAAArE,KAAAkE,GAEAE,QAAAC,EAAAL,MAAAK,EAAA7G,OAAAE,EAAA2G,EAAA7G,QAAAqD,KAAA,IAEA,CAMA,OADAwD,EAAAA,EAAAxD,KAAA,KACAwD,CACA,CAGAC,EACA,CACA,CAEA,oBAAA3G,SACAA,OAAAC,QAAA,CAAAG,UHuQA,CA5UC","file":"../text_tools.min.js","sourcesContent":[null,"function coinFlip() {\n\treturn Math.random() > 0.5;\n}\n\nfunction choice(choices) {\n\tif (!Array.isArray(choices)) choices = [...arguments];\n\treturn choices[Math.floor(Math.random() * choices.length)];\n}\n\nfunction chance(n) {\n\treturn Math.random(1) < n;\n}\n\nif (typeof module !== 'undefined') {\n\tmodule.exports = { coinFlip, choice, chance };\n}","/*\n\tadd a grammar and generate text\n\talso uses filters to add specific words or types of sentences\n\ttagChance - chance of including tag in filters\n\tfilterChance - \n\tremoveChange - change of being removed from filter\n\n*/\n\nif (typeof module !== 'undefined') {\n\tconst { coinFlip, choice, chance } = require('./cool.js');\n\tconst { Markov } = require('./Markov.js');\n}\n\nfunction CFGGenerator(params) {\n\n\tif (!params) params = {};\n\tlet { cfgFiles, tagChance, filterChance, removeChance, callback } = params;\n\n\tlet grammars = {};\n\tlet markovs = {};\n\tlet overrides = {};\n\tlet shareOverrides = params.shareOverrides !== undefined ? params.shareOverrides : true;\n\tlet defaultTypes = 'SQEF';\n\tlet defaultMarkovParams = { n: 3, max: 13 };\n\n\tlet defaultSentenceType = params.defaultSentenceType || 'S';\n\tlet useMarkov = params.useMarkov || false;\n\n\tlet overrideAddTagChance = tagChance || 0.5; // chance tag is added when going through new sent\n\tlet overrideFilterChance = filterChance || 0.5; // chance pos is added to filter for pos tags\n\tlet overrideRemoveChance = removeChance || 0.5;\n\n\t// this is relative to each user\n\tlet overridePosKeys = {}; \n\tlet overrideFilter = {};\n\t\n\tthis.isReady = false;\n\tif (cfgFiles) {\n\t\tif (Object.keys(cfgFiles).length > 0) {\n\t\t\tloadGrammarFiles();\n\t\t}\n\t}\n\n\tasync function loadGrammarFiles() {\n\t\tfor (const f in cfgFiles) {\n\t\t\tconst url = cfgFiles[f];\n\t\t\tconst cfgData = await fetch(url).then(response => response.json());\n\t\t\t// grammars[f] = cfgData;\n\t\t\tthis.feed(f, cfgData);\n\t\t}\n\t\t// if (callback) callback();\n\t}\n\n\tthis.feed = function(gid, json) {\n\t\tif (!overrides[gid]) overrides[gid] = {};\n\t\tif (!grammars[gid]) grammars[gid] = {};\n\t\tif (!markovs[gid]) markovs[gid] = {};\n\t\t\n\t\tfor (const k in json) {\n\t\t\tgrammars[gid][k] = json[k];\n\t\t\t\n\t\t\tif (useMarkov && defaultTypes.includes(k)) {\n\t\t\t\tmarkovs[gid][k] = new Markov(defaultMarkovParams);\n\t\t\t\tfor (let i = 0; i < json[k].length; i++) {\n\t\t\t\t\tlet seq = [...json[k][i]];\n\t\t\t\t\tseq.pop(); // remove punc\n\t\t\t\t\tmarkovs[gid][k].feed(seq.join(' '));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (!overridePosKeys[gid]) overridePosKeys[gid] = [];\n\t\tif (!overrideFilter[gid]) overrideFilter[gid] = [];\n\t\toverridePosKeys[gid] = overridePosKeys[gid]\n\t\t\t.concat(Object.keys(grammars[gid]).filter(k => k.length > 1));\n\t\toverrideFilter[gid] = overrideFilter[gid]\n\t\t\t.concat(overridePosKeys[gid].filter(_ => chance(overrideFilterChance)));\n\n\t\tif (!this.isReady && Object.keys(grammars[gid]).length > 0) { \n\t\t\tthis.isReady = true;\n\t\t\tif (callback) callback();\n\t\t}\n\t}\n\n\tfunction expand(gid, start, expansion, override, filter, prev) {\n\t\t// console.log('expand', start, override)\n\t\tif (override[start]) {\n\t\t\tif (override[start].length > 0) {\n\t\t\t\tlet pick = choice(override[start]);\n\t\t\t\tif (Array.isArray(pick)) {\n\t\t\t\t\tfor (let i = 0; i < pick.length; i++) {\n\t\t\t\t\t\texpand(gid, pick[i], expansion, override, filter, start);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif (start === '@&') console.log('@&', pick);\n\t\t\t\t\texpansion.push({ word: pick, pos: start });\n\t\t\t\t\t// remove to avoid doubles (optional?)\n\t\t\t\t\t// console.log('ex', override[start])\n\t\t\t\t\toverride[start].splice(override[start].indexOf(pick), 1);\n\t\t\t\t}\n\t\t\t\treturn expansion;\n\t\t\t}\n\t\t}\n\t\tif (grammars[gid][start]) {\n\t\t\t// if there's a filter, filter options to include POS in filter\n\t\t\tlet picks = filter[start] ? \n\t\t\t\tgrammars[gid][start].filter(p => p.includes(filter[start])):\n\t\t\t\tgrammars[gid][start];\n\t\t\tlet pick;\n\t\t\tif (picks.length === 0) {\n\t\t\t\tpick = choice(grammars[gid][start]);\n\t\t\t} else {\n\t\t\t\tpick = choice(picks);\n\t\t\t}\n\t\t\t// if (defaultTypes.includes(start)) console.log(pick.join(' '));\n\t\t\tfor (let i = 0; i < pick.length; i++){\n\t\t\t\texpand(gid, pick[i], expansion, override, filter, start);\n\t\t\t}\n\t\t} else {\n\t\t\t// prev is the prev pos, added to accomodate filters and overrides\n\t\t\t// console.log('start', start, 'prev', prev, 'ex', expansion);\n\t\t\tlet word = start;\n\t\t\tlet pos = prev;\n\t\t\tif (start === '@&') word = expansion[expansion.length - 1].word;\n\t\t\tif (start[0] === '@') {\n\t\t\t\tpos = start.substring(1);\n\t\t\t\tfor (let i = expansion.length - 1; i >= 0; i--) {\n\t\t\t\t\tif (expansion[i].pos === pos) {\n\t\t\t\t\t\tword = expansion[i].word;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\texpansion.push({ word: word, pos: pos });\n\t\t}\n\t\treturn expansion;\n\t}\n\n\tfunction formatSentence(expansion) {\n\t\tlet text = expansion.map(e => e.word).join(' ');\n\t\ttext = text.replace(/\\s+(?=[.?!,—])/g, ''); // remove trailing spaces\n\t\t// text = text.replace(/^\\s+/, ''); // remove beginning spaces\n\t\ttext = text.replace(/\\ba (?=[aeiou])/gi, 'an '); // replace a's with an's\n\t\ttext = text.replace(/\\ban (?![aeiou])/gi, 'a '); // replace an's w a's\n\t\t// text = text.replace(/ \\' /g, '\\''); // remove spaces from of '\n\t\ttext = text.replace(/\\bi\\b/g, 'I'); // capitalize i\n\t\ttext = text.replace(/\\s\\'s'/g, \"'s\"); // remove space from NNP 's\n\t\ttext = text[0].toUpperCase() + text.substring(1, text.length); // capitalize first letter\n\n\t\t// capitalize after punctuation\n\t\tlet puncs = text.match(/[\\.\\?\\!]\\s[a-z]/g);\n\t\tif (puncs) {\n\t\t\tpuncs.forEach(m => {\n\t\t\t\tlet r = m.substring(0, m.length - 1) + m[m.length - 1].toUpperCase();\n\t\t\t\ttext = text.replace(m, r);\n\t\t\t});\n\t\t}\n\n\t\treturn text;\n\t}\n\n\tthis.addOverrides = function(gid, tags, tagChance) {\n\t\t\n\t\tif (!overrides[gid]) { // usually not the case \n\t\t\toverrides[gid] = {};\n\t\t\toverridePosKeys[gid] = Object.keys(grammars[gid]).filter(k => k.length > 1);\n\t\t\toverrideFilter[gid] = overridePosKeys[gid].filter(_ => chance(overrideFilterChance));\n\t\t}\n\n\t\tconst gids = shareOverrides ? Object.keys(grammars) : [gid];\n\t\t// do here or in getSentence??\n\n\t\tfor (let i = 0; i < gids.length; i++) {\n\t\t\tconst g = gids[i];\n\t\t\tfor (let i = 0; i < tags.length - 1; i++) {\n\t\t\t\tif (!chance(tagChance || 0)) continue;\n\t\t\t\tconst { pos, word } = tags[i];\n\t\t\t\tif (!overrideFilter[g].includes(pos)) continue;\n\t\t\t\tif (!overrides[g][pos]) overrides[g][pos] = [];\n\t\t\t\tif (!overrides[g][pos].includes(word)) {\n\t\t\t\t\toverrides[g][pos].push(word);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t};\n\n\t// by gid or not ....\n\tthis.updateOverrides = function(gid, removeChance) {\n\t\t// randomly remove pos from overrides\n\t\tfor (const pos in overrides[gid]) {\n\t\t\tif (chance(removeChance)) {\n\t\t\t\toverrides[gid][pos].shift();\n\t\t\t}\n\t\t}\n\t\t// update filter\n\t\tif (chance(removeChance)) overrideFilter[gid].shift();\n\t\tif (chance(removeChance)) overrideFilter[gid].push(choice(overridePosKeys[gid].filter(pos => !overrideFilter[gid].includes(pos))));\n\t};\n\n\t// for testing ... \n\tthis.clearOverrides = function() {\n\t\tfor (const gid in overrides) {\n\t\t\toverrides[gid] = {};\n\t\t}\n\t};\n\n\t// gid = grammar Id, st = sentence type (SQEF)\n\t// add override - add words to override filter\n\tthis.getSentence = function(gid, st, addOverrides, filter) {\n\t\tlet over = { ...overrides[gid] };\n\t\tif (useMarkov) over[st] = [[...markovs[gid][st].getSequence().split(' '), '.']]; ;\n\t\tlet sent = this.getText(gid, st, over, filter);\n\t\tif (addOverrides) {\n\t\t\tthis.addOverrides(gid, sent.tags, overrideAddTagChance);\n\t\t\tthis.updateOverrides(gid, overrideRemoveChance);\n\t\t}\n\t\treturn sent.text;\n\t};\n\n\t// filter prefers sequences containing pos in filter\n\tthis.getText = function(gid, st, override, filter) {\n\t\tlet sentenceType = st || defaultSentenceType;\n\t\tif (typeof override === 'string') override = JSON.parse(override);\n\t\tif (!override[st]) {\n\t\t\tif (!grammars[gid][st]) st = 'S';\n\t\t\tif (!grammars[gid][st].length) st = 'S';\n\t\t}\n\t\tlet result = expand(gid, st, [], override || {}, filter || {});\n\t\t// maybe can add tags directly to filter here ... \n\t\treturn { text: formatSentence(result), tags: result };\n\t};\n}\n\nif (typeof module !== 'undefined') {\n\tmodule.exports = { CFGGenerator };\n}\n\nif (typeof window !== 'undefined') {\n\twindow.CFGGenerator = CFGGenerator;\n}\n","if (typeof module !== 'undefined') {\n\tconst { coinFlip, choice, chance } = require('./cool.js');\n}\n\nfunction Markov(params) {\n\tn = Number(params.n);\n\tmax = Number(params.max);\n\t\n\tlet ngrams = {};\n\tlet beginnings = [];\n\tlet byWord = true;\n\n\tfunction tokenize(text) {\n\t\treturn text.split(/\\s+/);\n\t}\n\n\tthis.feed = function(text) {\n\t\tlet tokens = tokenize(text);\n\t\tif (tokens.length < n) return false; // Discard this line if it's too short\n\n\t\t// Store the first ngram of this line\n\t\tlet beginning = tokens.slice(0, n).join(' ');\n\t\tbeginnings.push(beginning);\n\n\t\t// Now let's go through everything and create the dictionary\n\t\tfor (let i = 0; i < tokens.length - n; i++) {\n\t\t\tlet gram, next; // Current ngram and the next one\n\n\t\t\tgram = tokens.slice(i, i + n).join(' ');\n\t\t\tnext = tokens[i + n];\n\n\t\t\tif (!ngrams.hasOwnProperty(gram)) ngrams[gram] = []; // Is this a new one?\n\t\t\tngrams[gram].push(next); // Add to the list\n\t\t}\n\t}\n\n\tfunction generate() {\n\n\t\t// Get a random  beginning\n\t\tcurrent = choice(beginnings); // not sure why this is not let\n\t\tlet output = tokenize(current);\n\n\t\t// Generate a new token max number of times\n\t\tfor (let i = 0; i < max; i++) {\n\t\t\t// console.log(i, max, current);\n\t\t\tif (ngrams.hasOwnProperty(current)) { // If this is a valid ngram\n\t\t\t\tlet possibleNext = ngrams[current]; // What are all the possible next tokens\n\t\t\t\t// console.log(possibleNext)\n\t\t\t\tlet next = choice(possibleNext); // Pick one randomly\n\n\t\t\t\toutput.push(next);  // If by word store the answer in an array\n\t\t\t\t\t// lookup next with last ngram\n\t\t\t\tcurrent = output.slice(output.length - n, output.length).join(' ') \n\n\t\t\t} else {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\toutput = output.join(' ');\n\t\treturn output;\n\t}\n\n\tthis.getSequence = function() {\n\t\treturn generate();\n\t};\n}\n\nif (typeof module !== 'undefined') {\n\tmodule.exports = { Markov };\n}"]}